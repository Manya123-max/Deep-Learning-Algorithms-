{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy1TZMU2fbCxYqBBO5hQfG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manya123-max/Deep-Learning-Algorithms-/blob/main/DeepLab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi9KGZHv9ym_",
        "outputId": "8eb27f18-9540-4300-d9a9-1d43280530ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfiV2WmcS3_8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import os\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR problem data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input data\n",
        "y = np.array([0, 1, 1, 0])  # Labels (XOR output)"
      ],
      "metadata": {
        "id": "_y9hgPvdTgZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequential model\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "r8c1rTqZTkwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add input and first hidden layer with 2 neurons and ReLU activation\n",
        "model.add(Dense(2, input_dim=2, activation='relu'))\n",
        "\n",
        "# Add output layer with 1 neuron and sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXVP_0_bT2VQ",
        "outputId": "15c1c97b-51e9-4a82-d76a-573719914fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "m9n5ERb_UftZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=1)  # Set verbose=0 to suppress training logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsBaWpYbUocJ",
        "outputId": "843d8811-7350-42f1-9a74-52a2d3b40270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1000 - loss: 0.7220  \n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 0.7370      \n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2667 - loss: 0.6788     \n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4667 - loss: 0.6633 \n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 0.7360      \n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 0.7521     \n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.7122  \n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.7255  \n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4333 - loss: 0.6796     \n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6440 \n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.7116  \n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.6901      \n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5667 - loss: 0.6495 \n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6333 - loss: 0.6600 \n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4333 - loss: 0.7251     \n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.6621 \n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6362  \n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 0.7331     \n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.6617  \n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7215     \n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4333 - loss: 0.6961     \n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.6397  \n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6333 - loss: 0.6885 \n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4333 - loss: 0.7218\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.6440 \n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.6686 \n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2667 - loss: 0.7526     \n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6441 \n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.6901     \n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6754 \n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2667 - loss: 0.7300     \n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7297     \n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2667 - loss: 0.7191     \n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3667 - loss: 0.7154      \n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 0.7159      \n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3667 - loss: 0.7177     \n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5667 - loss: 0.7158 \n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.7418      \n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6333 - loss: 0.7021 \n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6333 - loss: 0.7019  \n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2667 - loss: 0.7445     \n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.6816      \n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.6739  \n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 0.6508  \n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.7403      \n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2667 - loss: 0.7166     \n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7333 - loss: 0.6382\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 0.7049  \n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6437  \n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 0.7159      \n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4333 - loss: 0.7100      \n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 0.7252      \n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.7233      \n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.7038  \n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6673  \n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 0.6803      \n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6553 \n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3667 - loss: 0.6879      \n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.7115      \n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.6578  \n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.7335      \n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4333 - loss: 0.7057     \n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.7116      \n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.6509 \n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6333 - loss: 0.6851 \n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.7318      \n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.6849  \n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6333 - loss: 0.6847 \n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2667 - loss: 0.7349     \n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.6871      \n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5667 - loss: 0.6501  \n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3667 - loss: 0.7298     \n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6703  \n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3667 - loss: 0.7052     \n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2667 - loss: 0.7199      \n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6660  \n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6426 \n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.6860      \n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3667 - loss: 0.6854     \n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7333 - loss: 0.6698 \n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5667 - loss: 0.6993 \n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3667 - loss: 0.7078      \n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2667 - loss: 0.7089     \n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6385  \n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.6552  \n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6383  \n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2667 - loss: 0.7200     \n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7333 - loss: 0.6686 \n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2667 - loss: 0.7275     \n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6649 \n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6682 \n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 0.6780      \n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.6645 \n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6818  \n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6415  \n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 0.6486  \n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.6968     \n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.7053     \n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2667 - loss: 0.7158      \n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.6902      \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78529cd08df0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0GRXqEnU0Sa",
        "outputId": "357bd89e-3d46-4e84-8543-63a302c4c26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Display the predictions in a readable format\n",
        "print(\"Predictions:\")\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"Input: {X[i]} => Predicted Output: {prediction[0]:.4f} (rounded: {round(prediction[0])})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqKDokMfqD0e",
        "outputId": "2d82c0d7-6aaa-4d19-822a-987abe77127f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "Predictions:\n",
            "Input: [0 0] => Predicted Output: 0.4943 (rounded: 0)\n",
            "Input: [0 1] => Predicted Output: 0.5754 (rounded: 1)\n",
            "Input: [1 0] => Predicted Output: 0.4846 (rounded: 0)\n",
            "Input: [1 1] => Predicted Output: 0.5393 (rounded: 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each layer and print weights and biases\n",
        "for layer in model.layers:\n",
        "    weights = layer.get_weights()\n",
        "    print(f\"Layer: {layer.name}\")\n",
        "    for i, weight in enumerate(weights):\n",
        "       print(f\"Weight {i}: {weight.shape}\")\n",
        "       print(weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2W8yCv3mWb2",
        "outputId": "f8ab7780-58cd-47ce-dbbb-7989bf830533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: dense\n",
            "Weight 0: (2, 2)\n",
            "[[1.071092  0.9150635]\n",
            " [1.0443197 1.1751966]]\n",
            "Weight 1: (2,)\n",
            "[-0.08785265  0.00029753]\n",
            "Layer: dense_1\n",
            "Weight 0: (2, 1)\n",
            "[[-1.2294524]\n",
            " [ 1.2787117]]\n",
            "Weight 1: (1,)\n",
            "[-0.02307088]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model to file for later use\n",
        "model.save('simple_nn_model.keras')\n",
        "\n",
        "# Load the saved model from a file\n",
        "loaded_model = tf.keras.models.load_model('simple_nn_model.keras')"
      ],
      "metadata": {
        "id": "pK7XzYCqqFyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# b) McCulloch-Pitts Model"
      ],
      "metadata": {
        "id": "VshVdK-IqfV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf # Import tensorflow"
      ],
      "metadata": {
        "id": "0zYCmjd3qk_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary input data for AND gate\n",
        "X = np.array([ [0, 0],[0, 1],[1, 0],[1, 1]])\n",
        "# Target output for AND gate\n",
        "y = np.array([0, 0, 0, 1])\n"
      ],
      "metadata": {
        "id": "WZmwxEo9-FnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=1)  # Set verbose=0 to suppress training logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffaf9d78-00e7-4c3f-b997-a7afae67dab7",
        "id": "4SPNNlnfqftJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8333 - loss: 0.6996\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5333 - loss: 0.7440\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7491      \n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9000 - loss: 0.6651\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6672  \n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.6802  \n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6761  \n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6918  \n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.7403      \n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.7071  \n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.7367      \n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.6826 \n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.7281      \n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.7266     \n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7261     \n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6981  \n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.6839  \n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9000 - loss: 0.6600 \n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.7175      \n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6580  \n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6982  \n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7125      \n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.6821 \n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.7077      \n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.7101      \n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.7168      \n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7333 - loss: 0.6986 \n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.6486 \n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2667 - loss: 0.7105      \n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6576 \n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.6700     \n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2667 - loss: 0.7077      \n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.6872     \n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.6948     \n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6535  \n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6333 - loss: 0.6649 \n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 0.6754  \n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2667 - loss: 0.7018     \n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6691 \n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.6886     \n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6627 \n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.6841     \n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2667 - loss: 0.6968     \n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 0.6754     \n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6456 \n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4333 - loss: 0.6722     \n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 0.6986     \n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6599 \n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.6768     \n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.6432 \n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 0.6852     \n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6261 \n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3667 - loss: 0.6828      \n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2667 - loss: 0.6873     \n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 0.6608     \n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4333 - loss: 0.6718     \n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.6333  \n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.6379 \n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.6654  \n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4333 - loss: 0.6555      \n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6310 \n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4333 - loss: 0.6599     \n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.6796      \n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.6785      \n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6124  \n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6108 \n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6095 \n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.6544 \n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6710     \n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6520 \n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.6112 \n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6414 \n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.6262 \n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6200 \n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6380 \n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6744     \n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6874     \n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6751 \n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6744 \n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6860     \n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6853     \n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6240 \n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6033 \n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6763     \n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6381 \n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6855     \n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5333 - loss: 0.6848     \n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.6521 \n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6087 \n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6211 \n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6145 \n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.5935 \n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.5918 \n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6747     \n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6650     \n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6871     \n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.6124 \n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 0.6811     \n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6325 \n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.5847 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78529cc4b190>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "print(predictions.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0I5gx6LrRyj",
        "outputId": "fc9c5217-24de-4509-d20e-0df44ca96576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "[0.4428179  0.47287378 0.39673516 0.45551154]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom binary step activation function\n",
        "def binary_step(x):\n",
        " return tf.where(x >= 0, 1, 0)\n",
        "# Create a Keras model\n",
        "model = Sequential()\n",
        "# Add a single Dense layer with binary step activation\n",
        "model.add(Dense(1, input_dim=2, activation=binary_step))\n",
        "\n",
        "''' Compile the model using a loss function (binary cross-entropy) and a simple optimizer\n",
        "(Stochastic Gradient Descent). Note that the binary step function is not differentiable, so the usual\n",
        "backpropagation won't work. We'll manually set the weights.'''\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ImgSiw_b-Hgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_step = binary_step(predictions)\n",
        "predictions_step = tf.keras.backend.flatten(predictions_step)"
      ],
      "metadata": {
        "id": "syhx_EHnsWxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(predictions_step)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_zi1WBJrkM7",
        "outputId": "496a371f-11b2-43d8-cdb7-3734c2ab67da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a grid of points\n",
        "x1_vals = np.linspace(-0.1, 1.1, 100)  # Values from slightly below 0 to slightly above 1\n",
        "x2_vals = np.linspace(-0.1, 1.1, 100)\n",
        "xx1, xx2 = np.meshgrid(x1_vals, x2_vals)\n",
        "grid_points = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "\n",
        "# Predict for each point in the grid\n",
        "grid_preds = model.predict(grid_points)\n",
        "grid_preds = binary_step(grid_preds).numpy()\n",
        "\n",
        "# Reshape the predictions back into the shape of the grid\n",
        "grid_preds = grid_preds.reshape(xx1.shape)\n",
        "\n",
        "# Plot the decision boundary and data points\n",
        "plt.contourf(xx1, xx2, grid_preds, alpha=0.75, cmap='coolwarm')\n",
        "\n",
        "# Draw a contour line at the decision boundary where predictions change from 0 to 1\n",
        "plt.contour(xx1, xx2, grid_preds, levels=[0.5], colors='black', linestyles='--')\n",
        "\n",
        "# Plot the data points (AND gate inputs)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, marker='o', edgecolor='k', s=100, cmap='coolwarm', label='Data points')\n",
        "\n",
        "plt.xlabel('Input 1')\n",
        "plt.ylabel('Input 2')\n",
        "plt.title('Decision Boundary of McCulloch-Pitts AND Gate')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "qfaVhRe4YU4E",
        "outputId": "22a8276a-54ed-45d5-ce60-89079a3dbe18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}